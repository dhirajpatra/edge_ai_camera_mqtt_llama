# üß† Edge AI Microservices with LLaMA 3.2 1B (Quantized) using `llama.cpp`

This project demonstrates a lightweight yet scalable **Edge AI microservice architecture**, where:

![Edge AI Microservice Architecture](./images/edge_ai_architecture.png)
![Face detection and sharing by MQTT Message broker](./images/1.png)
![LLM Message](./images/2.png)

* A **camera detection service** performs real-time object detection.
* An **LLM service** (powered by a quantized LLaMA 3.2 1B model via [`llama.cpp`](https://github.com/ggerganov/llama.cpp)) generates intelligent responses.
* Communication happens over **MQTT** using a broker (e.g., Mosquitto).

You can **swap models** and **scale components independently** across devices (e.g., Raspberry Pi, edge boxes, laptops), thanks to its fully containerized microservice design.

---

## üöÄ Features

* ‚öôÔ∏è Distributed microservices architecture
* üì¶ Docker + Docker Compose deployment
* üß† Lightweight quantized LLM (customizable)
* üì° MQTT-based communication between services
* üì∑ Edge device compatibility (e.g., Raspberry Pi, microcontrollers)

---

## üì¶ Services

| Service          | Description                                    |
| ---------------- | ---------------------------------------------- |
| `llm_service`    | LLaMA 3.2 1B Quantized model via llama.cpp     |
| `camera_service` | Real-time object detection (OpenCV/TensorFlow) |
| `mqtt_broker`    | Mosquitto MQTT Broker                          |
| `api_gateway`    | REST/HTTP gateway (optional UI integration)    |

---

## üíª System 1: Laptop (Intel i5 / 32GB RAM)

### ‚úÖ Prerequisites

* Python 3.10+
* Docker & Docker Compose
* MQTT broker (Mosquitto)
* Quantized `.gguf` model (e.g., `Llama-3.2-1B-Instruct-Q4_0` from TheBloke)

### üìÅ Folder Structure

```
llm_service/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ llama-3.2-1b-q4_0.gguf
```

### ‚ñ∂Ô∏è Run with Docker Compose

```bash
docker-compose -f docker-compose.laptop.yml up --build --remove-orphans
```

> This builds all services and removes unused containers.

---

## üçì System 2: Raspberry Pi 4 (4GB/8GB)

### ‚úÖ Prerequisites

* Raspberry Pi OS 64-bit
* Docker & Docker Compose
* Optional: Mosquitto for local MQTT

### ‚öôÔ∏è Build for ARM64

```bash
docker buildx build --platform linux/arm64 -t llm_service ./llm_service
```

### ‚ñ∂Ô∏è Run

```bash
docker run -v $(pwd)/models:/app/models --network host llm_service
```

> Use `--network host` if Mosquitto runs locally on the Pi.

---

## üîó MQTT Topics

| Topic          | Purpose                         |
| -------------- | ------------------------------- |
| `detections`   | Input: object detection events  |
| `llm_response` | Output: LLM-generated responses |

---

## üì• Download Models

Download `.gguf` quantized models from:

* [TheBloke on Hugging Face](https://huggingface.co/TheBloke)
* Suggested: `bartowski/Llama-3.2-1B-Instruct-GGUF`

Place them in: `llm_service/models/`.

---

## ‚ö†Ô∏è System Tips

* Run: `ls /dev/video*` to identify camera device
* Add user permission: `sudo usermod -aG video $USER`
* Use swap on Raspberry Pi to manage memory
* Tune `n_threads` and context size for optimal performance

---

## üîú Coming Soon

* `camera_service/`: Real-time detection via OpenVINO/TensorFlow
* UI Dashboard (for interactions)
* Metrics & Logging

---

## ü§ù Contributions

We welcome contributions:

1. Fork & branch: `feature/your-feature-name`
2. Follow structure & style
3. Test before pushing
4. Submit a PR with description

For major changes, raise an issue first.

---
